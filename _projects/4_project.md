---
layout: page
title: RUTAS - Multimodal Emotion Understanding for Human-Robot Interaction
description: Consolidated project line combining pose estimation, multimodal fusion, and adaptive emotion-aware robot behavior.
img: assets/img/6.jpg
importance: 4
category: fun
---

This page consolidates three earlier projects into a single line of work, referred to here as **RUTAS**.

## Integrated Project Components

- Emotion detection system for human-robot interaction (2021-2022).
- Multimodal emotion recognition from images (2020-2021).
- Comparison of human pose estimation methods (2019).

## Core Ideas

- Combine posture, facial, and scene information for emotion understanding.
- Evaluate fusion strategies for multimodal signals.
- Build practical pipelines where emotion recognition can adapt robot behavior.

## Outputs

- Experimental reproductions of state-of-the-art pose estimation methods.
- Multimodal fusion workflows for emotion recognition.
- Foundations that later supported publications in robotics and multimodal affect analysis.
